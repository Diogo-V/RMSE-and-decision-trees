{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports definition\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm as vector_norm\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_var = {\n",
    "    \"y0\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],  # Does not belong in the table\n",
    "    \"y1\": [1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0],\n",
    "    \"y2\": [1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0],\n",
    "    \"y3\": [0.0, 5.0, 4.0, 3.0, 7.0, 1.0, 2.0, 9.0],\n",
    "    \"output\": [1.0, 3.0, 2.0, 0.0, 6.0, 4.0, 5.0, 7.0]\n",
    "}\n",
    "\n",
    "test_var = {\n",
    "    \"y0\": [1.0, 1.0],  # Does not belong in the table\n",
    "    \"y1\": [2.0, 0.0],\n",
    "    \"y2\": [0.0, 2.0],\n",
    "    \"y3\": [0.0, 1.0],\n",
    "    \"output\": [2.0, 4.0]\n",
    "}\n",
    "\n",
    "df_train = pd.DataFrame.from_dict(train_var)\n",
    "df_test = pd.DataFrame.from_dict(test_var)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    y0        y1    y2          y3  output\n",
      "0  1.0  1.414214   2.0    2.828427     1.0\n",
      "1  1.0  5.196152  27.0  140.296115     3.0\n",
      "2  1.0  4.472136  20.0   89.442719     2.0\n",
      "3  1.0  3.741657  14.0   52.383203     0.0\n",
      "4  1.0  7.280110  53.0  385.845824     6.0\n",
      "5  1.0  1.732051   3.0    5.196152     4.0\n",
      "6  1.0  2.828427   8.0   22.627417     5.0\n",
      "7  1.0  9.219544  85.0  783.661279     7.0\n"
     ]
    }
   ],
   "source": [
    "# Applies basis function to dataset to normalize it's values\n",
    "for index, row in df_train.iterrows():\n",
    "\n",
    "    # Calculates vector norm\n",
    "    vector = [row[\"y1\"], row[\"y2\"], row[\"y3\"]]\n",
    "    norm = vector_norm(vector)\n",
    "\n",
    "    # Updates row's values according to basis function\n",
    "    row[\"y1\"] = norm ** 1\n",
    "    row[\"y2\"] = norm ** 2\n",
    "    row[\"y3\"] = norm ** 3\n",
    "\n",
    "# Applies basis function to dataset to normalize it's values\n",
    "for index, row in df_test.iterrows():\n",
    "\n",
    "    # Calculates vector norm\n",
    "    vector = [row[\"y1\"], row[\"y2\"], row[\"y3\"]]\n",
    "    norm = vector_norm(vector)\n",
    "\n",
    "    # Updates row's values according to basis function\n",
    "    row[\"y1\"] = norm ** 1\n",
    "    row[\"y2\"] = norm ** 2\n",
    "    row[\"y3\"] = norm ** 3\n",
    "\n",
    "print(df_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Gathers vars\n",
    "X_train = df_train.drop(\"output\", axis=1).to_numpy()\n",
    "y_train = df_train[\"output\"].to_numpy()\n",
    "\n",
    "X_test = df_test.drop(\"output\", axis=1).to_numpy()\n",
    "y_test = df_test[\"output\"].to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [2.45360697 2.35072931]\n",
      "1.2095150071840008\n"
     ]
    }
   ],
   "source": [
    "# Creates a linear regression model (we wont need a polynomial because the data has been transformed) and trains it\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Predicts values and calculates RMSE\n",
    "predictions = reg.predict(X_test)\n",
    "print(f\"predictions: {predictions}\")\n",
    "error = math.sqrt(np.square(np.subtract(y_test, predictions)).mean())\n",
    "print(error)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      " [[  1.           1.41421356   2.           2.82842712]\n",
      " [  1.           5.19615242  27.         140.29611541]\n",
      " [  1.           4.47213595  20.          89.4427191 ]\n",
      " [  1.           3.74165739  14.          52.38320341]\n",
      " [  1.           7.28010989  53.         385.84582413]\n",
      " [  1.           1.73205081   3.           5.19615242]\n",
      " [  1.           2.82842712   8.          22.627417  ]\n",
      " [  1.           9.21954446  85.         783.66127887]]\n",
      "Z: \n",
      " [1. 3. 2. 0. 6. 4. 5. 7.]\n",
      "Xt: \n",
      " [[  1.           1.           1.           1.           1.\n",
      "    1.           1.           1.        ]\n",
      " [  1.41421356   5.19615242   4.47213595   3.74165739   7.28010989\n",
      "    1.73205081   2.82842712   9.21954446]\n",
      " [  2.          27.          20.          14.          53.\n",
      "    3.           8.          85.        ]\n",
      " [  2.82842712 140.29611541  89.4427191   52.38320341 385.84582413\n",
      "    5.19615242  22.627417   783.66127887]]\n",
      "Xt.X: \n",
      " [[8.00000000e+00 3.58842916e+01 2.12000000e+02 1.48228114e+03]\n",
      " [3.58842916e+01 2.12000000e+02 1.48228114e+03 1.14360000e+04]\n",
      " [2.12000000e+02 1.48228114e+03 1.14360000e+04 9.35735164e+04]\n",
      " [1.48228114e+03 1.14360000e+04 9.35735164e+04 7.93976000e+05]]\n",
      "(Xt.X)^-1: \n",
      " [[ 8.19551659e+00 -6.23130180e+00  1.30493618e+00 -7.93403820e-02]\n",
      " [-6.23130180e+00  5.07809653e+00 -1.10435916e+00  6.86446433e-02]\n",
      " [ 1.30493618e+00 -1.10435916e+00  2.47213974e-01 -1.56648460e-02]\n",
      " [-7.93403820e-02  6.86446433e-02 -1.56648460e-02  1.00683060e-03]]\n",
      "(Xt.X)^-1.Xt: \n",
      " [[ 1.76858894 -0.08114793 -0.66940817 -1.00687669  1.37941711  0.90512909\n",
      "  -0.78504493 -0.51065743]\n",
      " [-1.06435077 -0.03185877  0.5312166   0.90399365 -1.30698763 -0.39217006\n",
      "   0.85010185  0.51005512]\n",
      " [ 0.19325755  0.0435779  -0.09073507 -0.18677661  0.32320534  0.052375\n",
      "  -0.19540644 -0.13949766]\n",
      " [-0.01074414 -0.00434877  0.00440454  0.01093752 -0.02135529 -0.00220726\n",
      "   0.0122792   0.01103421]]\n",
      "(Xt.X)^-1.Xt.Z: \n",
      " [ 4.58352122 -1.6872048   0.33773733 -0.01330674]\n",
      "[1. 2. 4. 8.]\n",
      "prod1: 2.453606971151091 | prod2: 2.3507293063508232\n"
     ]
    }
   ],
   "source": [
    "# Calculates W\n",
    "print(\"X: \\n\", X_train)\n",
    "print(\"Z: \\n\", y_train)\n",
    "xt = np.matrix.transpose(X_train)\n",
    "print(\"Xt: \\n\", xt)\n",
    "m1 = np.matmul(xt, X_train)\n",
    "print(\"Xt.X: \\n\", m1)\n",
    "inverse = np.linalg.inv(m1)\n",
    "print(f\"(Xt.X)^-1: \\n\", inverse)\n",
    "m2 = np.matmul(inverse, xt)\n",
    "print(f\"(Xt.X)^-1.Xt: \\n\", m2)\n",
    "w = np.matmul(m2, y_train)\n",
    "print(f\"(Xt.X)^-1.Xt.Z: \\n\", w)\n",
    "\n",
    "# Predicts y\n",
    "print(X_test[0])\n",
    "prod_1 = np.dot(w, X_test[0])\n",
    "prod_2 = np.dot(w, X_test[1])\n",
    "print(f\"prod1: {prod_1} | prod2: {prod_2}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}